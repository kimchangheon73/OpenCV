{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "from turtle import width\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# 얼굴을 찾고, 찾은 얼굴에 표시를 해주기 위한 변수 정의\n",
    "mp_face_detection = mp.solutions.face_detection         # 얼굴 검출을 위한 face_detection 모듈을 사용\n",
    "mp_drawing = mp.solutions.drawing_utils                 # 얼굴의 특징을 그리기 위한 drawing_utils 모듈을 사용\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "\n",
    "# model_selection : face-dection 객체를 만들 때 상황(0 : 1 = 근거리영상 : 원거리영상 )에 맞는 영상에 따라 선택\n",
    "# min_detection_confidence : 얼굴로 판단할 어느정도의 신뢰도를 정의 (treshold와 비슷한 개념)\n",
    "with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.7) as face_detection:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = face_detection.process(image)                 # process : 이미지로부터 얼굴을 검출해 결과를 반환하는 함수 \n",
    "\n",
    "        # Draw the face detection annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        image = cv2.resize(image, (1920,1080))\n",
    "        \n",
    "        if results.detections:\n",
    "            # 6개의 특징을 추출 : 우좌/눈, 코 끝, 입중심, 우좌/귀( 귀구슬점, 이주 )\n",
    "            for detection in results.detections:\n",
    "                mp_drawing.draw_detection(image, detection)     # 얼굴이라고 인식하는 6부분에 점을 찍기\n",
    "                # print(detection)\n",
    "                \n",
    "                h, w, _ = image.shape\n",
    "                \n",
    "                keypoints = detection.location_data.relative_bounding_box\n",
    "                x = int(keypoints.xmin * w)\n",
    "                y = int(keypoints.ymin * h)\n",
    "                w = int(keypoints.width * w)\n",
    "                h = int(keypoints.height * h)\n",
    "                \n",
    "                crop = image[y:y+h, x :x+w]\n",
    "                \n",
    "                \n",
    "                image[y:y+h, x :x+w] = cv2.GaussianBlur(crop, (0,0), 33)\n",
    "                      \n",
    "                \n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.imshow('MediaPipe Face Detection', cv2.resize(image, None, fx=0.5, fy =0.5))\n",
    "        \n",
    "        if cv2.waitKey(5) == ord('q'):\n",
    "            print(image.shape)\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
